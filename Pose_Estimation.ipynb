{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ▶Install and Import Dependencies"
      ],
      "metadata": {
        "id": "LLeVSFeRV5Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python"
      ],
      "metadata": {
        "id": "jztVVvKkWBoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose=mp.solutions.pose\n"
      ],
      "metadata": {
        "id": "qYQOyt7GXBkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#▶Video Capture"
      ],
      "metadata": {
        "id": "0ZX9Je4DWCQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Video Capture\n",
        "cap=cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret,frame=cap.read()\n",
        "    cv2.imshow(\"Media Pipe\",frame)\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "w6gR1_jKWGBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#▶Make Detection"
      ],
      "metadata": {
        "id": "R967KZWoWHrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        \n",
        "        #Recolor the image to RGB\n",
        "        image= cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable=False\n",
        "        \n",
        "        #make detection\n",
        "        results=pose.process(image)\n",
        "        \n",
        "        #Recolor back to BGR\n",
        "        image.flags.writeable=True\n",
        "        image= cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        #Render the detections\n",
        "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
        "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
        "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2))\n",
        "        \n",
        "        cv2.imshow(\"Media Pipe\",image)\n",
        "        \n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "i2vVFjz-WM0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#▶Determining Joints"
      ],
      "metadata": {
        "id": "py1ByTnHWNeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        \n",
        "        #Recolor the image to RGB\n",
        "        image= cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable=False\n",
        "        \n",
        "        #make detection\n",
        "        results=pose.process(image)\n",
        "        \n",
        "        #Recolor back to BGR\n",
        "        image.flags.writeable=True\n",
        "        image= cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        #Extract Landmarks\n",
        "        try:\n",
        "            landmarks=results.pose_landmarks.landmark\n",
        "            # print(landmarks)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        #Render the detections\n",
        "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
        "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
        "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2))\n",
        "        \n",
        "        cv2.imshow(\"Media Pipe\",image)\n",
        "         \n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "FVmPTEkOWSkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#▶ Calculate Angles"
      ],
      "metadata": {
        "id": "cUiIgRTIWTlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Claculate angle\n",
        "def calculate_angle(a,b,c):\n",
        "    a=np.array(a)\n",
        "    b=np.array(b)\n",
        "    c=np.array(c)\n",
        "    \n",
        "    radians=np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
        "    angle=np.abs(radians*180.0/np.pi)\n",
        "    \n",
        "    if angle>180.0:\n",
        "        angle=360-angle\n",
        "        \n",
        "    return angle\n",
        "\n",
        "shoulder=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
        "elbow=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
        "wrist=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "\n",
        "angle=calculate_angle(shoulder,elbow,wrist)\n",
        "print(angle)\n",
        "\n",
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        \n",
        "        #Recolor the image to RGB\n",
        "        image= cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable=False\n",
        "        \n",
        "        #make detection\n",
        "        results=pose.process(image)\n",
        "        \n",
        "        #Recolor back to BGR\n",
        "        image.flags.writeable=True\n",
        "        image= cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        #Extract Landmarks\n",
        "        try:\n",
        "            landmarks=results.pose_landmarks.landmark\n",
        "            # print(landmarks)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        #Render the detections\n",
        "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
        "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
        "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2))\n",
        "        \n",
        "        cv2.imshow(\"Media Pipe\",image)\n",
        "         \n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "M56Q7IeXWY0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#▶Angle Calculation"
      ],
      "metadata": {
        "id": "1iXnCimQUHWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "angle calculation \n",
        "cap = cv2.VideoCapture(0)\n",
        "## Setup mediapipe instance\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        # Recolor image to RGB\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable = False\n",
        "      \n",
        "        # Make detection\n",
        "        results = pose.process(image)\n",
        "    \n",
        "        # Recolor back to BGR\n",
        "        image.flags.writeable = True\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        # Extract landmarks\n",
        "        try:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "            \n",
        "            # Get coordinates\n",
        "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
        "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
        "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "            \n",
        "            # Calculate angle\n",
        "            angle = calculate_angle(shoulder, elbow, wrist)\n",
        "            \n",
        "            # Visualize angle\n",
        "            cv2.putText(image, str(angle), \n",
        "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
        "                                )\n",
        "                       \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "        # Render detections\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
        "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
        "                                 )               \n",
        "        \n",
        "        cv2.imshow('Mediapipe Feed', image)\n",
        "\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "cJCTOiFIUolZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#▶Curl Counter"
      ],
      "metadata": {
        "id": "UJ7HQCsPWbgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#curl counter\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "#curl counter variables\n",
        "counter=0\n",
        "stage=None\n",
        "## Setup mediapipe instance\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        # Recolor image to RGB\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable = False\n",
        "      \n",
        "        # Make detection\n",
        "        results = pose.process(image)\n",
        "    \n",
        "        # Recolor back to BGR\n",
        "        image.flags.writeable = True\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        # Extract landmarks\n",
        "        try:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "            \n",
        "            # Get coordinates\n",
        "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
        "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
        "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "            \n",
        "            # Calculate angle\n",
        "            angle = calculate_angle(shoulder, elbow, wrist)\n",
        "            \n",
        "            # Visualize angle\n",
        "            cv2.putText(image, str(angle), \n",
        "                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
        "                                )\n",
        "            \n",
        "            #curl counter logic\n",
        "            if angle>160:\n",
        "                stage=\"down\"\n",
        "            if angle < 30 and stage==\"down\":\n",
        "                stage=\"up\"\n",
        "                counter+=1\n",
        "                print(counter)\n",
        "                       \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        #render curl counter\n",
        "        #setup status box\n",
        "        cv2.rectangle(image,(0,0),(225,73),(245,177,16),-1)\n",
        "        \n",
        "        #Rep data\n",
        "        cv2.putText(image,\"Reps\",(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
        "        cv2.putText(image,str(counter),(10,60),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2,cv2.LINE_AA)\n",
        "        \n",
        "        #Stage data\n",
        "        cv2.putText(image,\"Stage\",(65,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
        "        cv2.putText(image,stage,(60,60),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2,cv2.LINE_AA)   \n",
        "             \n",
        "         \n",
        "        # Render detections\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
        "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
        "                                 )               \n",
        "        \n",
        "        cv2.imshow('Mediapipe Feed', image)\n",
        "\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "oNH31DrLWfMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}